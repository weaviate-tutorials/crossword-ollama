{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook sets up a database and installs python modules to use with the crossword generator project. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the Weaviate client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clear your current pip cache\n",
    "# !pip cache purge\n",
    "\n",
    "# Uncomment to upgrade pip\n",
    "# !pip install --upgrade pip\n",
    "\n",
    "# Install client from public released\n",
    "!pip3 install --no-cache -U \"weaviate-client==4.*\"\n",
    "\n",
    "# Check installed client version\n",
    "!pip show weaviate-client | grep Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install additional Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the huggingface datasets\n",
    "# !pip install datasets\n",
    "\n",
    "# # Import tqdm progress monitor\n",
    "# !pip install tqdm\n",
    "\n",
    "# # Import pandas\n",
    "# !pip install pandas\n",
    "\n",
    "# Import the Ollama python client\n",
    "!pip install ollama\n",
    "\n",
    "# Import spacy named entity recognition for puzzle generation\n",
    "#    It might take a few minutes to build spacy and setup the data\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect the client to a local Weaviate instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "# Uncomment to check the connection\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the Ollama module is enabled\n",
    "\n",
    "Verify that the Ollama modules are configured.\n",
    "\n",
    "If they are not configured, enable the `text2vec-ollama` module and the `generative-ollama` module in your Weaviate [configuration file](/developers/weaviate/installation#configuration-files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_info = client.get_meta()\n",
    "if 'text2vec-ollama' not in meta_info[\"modules\"] :\n",
    "    print(\"Enable the text2vec-ollama module.\")\n",
    "\n",
    "if 'generative-ollama' not in meta_info[\"modules\"] :\n",
    "    print(\"Enable the generative-ollama module.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the collection name\n",
    "\n",
    "If a previous version of the collection exists, uncomment the code to delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the collection name\n",
    "collection = \"CrosswordPuzzles\"\n",
    "\n",
    "# # Uncomment to remove old versions of this collection\n",
    "# if (client.collections.exists(collection)):\n",
    "#     client.collections.delete(collection)\n",
    "#     print(f\"Removed old collection: {collection}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a collection\n",
    "\n",
    "The local collection holds some books on art from [Project Gutenberg](https://www.gutenberg.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLECTION DEFINITION\n",
    "\n",
    "from weaviate.classes.config import Configure\n",
    "\n",
    "# Remove old version of this collection if there is one\n",
    "if (client.collections.exists(collection)):\n",
    "    client.collections.delete(collection)\n",
    "    print(f\"Removed old collection: {collection}\")\n",
    "\n",
    "# Define the collection\n",
    "articles = client.collections.create(\n",
    "    name=collection,\n",
    "    description=\"Create a connection to Ollama\",\n",
    "    vectorizer_config=Configure.Vectorizer.text2vec_cohere(\n",
    "        model=\"embed-multilingual-v3.0\"\n",
    "    ),\n",
    "\n",
    "    generative_config=Configure.Generative.ollama(\n",
    "        api_endpoint=\"http://host.docker.internal:11434\",  # If using Docker, use this to contact your local Ollama instance\n",
    "        model=\"llama3\"  # The model to use, e.g. \"phi3\", or \"mistral\", \"command-r-plus\", \"gemma\"\n",
    "    )\n",
    "\n",
    "    generative_config=Configure.Generative.cohere(),\n",
    "    # Uncomment to compress the collection data\n",
    "    # vector_index_config=Configure.VectorIndex.hnsw(\n",
    "    # quantizer=Configure.VectorIndex.Quantizer.sq()\n",
    "    # ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK COLLECTION DEFINITION\n",
    "\n",
    "import pprint as pp\n",
    "\n",
    "# Print the collection definition\n",
    "collection_definition = client.collections.export_config(collection)\n",
    "pp.pprint(f\"Name: {collection_definition.name}     Description: {collection_definition.description}\")\n",
    "# Collection properties haven't been configured yet\n",
    "pp.pprint(collection_definition.properties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT WIKIPEDIA\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "wikipedia = client.collections.get(collection)\n",
    "\n",
    "def import_wiki_data(lang, num_rows, skip_rows):\n",
    "    dataset = load_dataset(\"Cohere/wikipedia-2023-11-embed-multilingual-v3\", lang, split=\"train\", streaming=True)\n",
    "    dataset = dataset.skip(skip_rows)\n",
    "\n",
    "    # Edit to change the batch size\n",
    "    batch_size = 1000\n",
    "\n",
    "    counter = skip_rows\n",
    "\n",
    "    with wikipedia.batch.fixed_size(batch_size=batch_size, concurrent_requests=4) as batch:\n",
    "        for item in tqdm(dataset.skip(skip_rows),\n",
    "                         initial=skip_rows,\n",
    "                         total=num_rows\n",
    "                        ):\n",
    "            vector = item[\"emb\"]\n",
    "\n",
    "            data_to_insert = {\n",
    "                \"wiki_id\": item[\"_id\"],\n",
    "                \"text\": item[\"text\"],\n",
    "                \"title\": item[\"title\"],\n",
    "                \"url\": item[\"url\"],\n",
    "                \"lang\": lang,\n",
    "            }\n",
    "\n",
    "            batch.add_object(\n",
    "                properties=data_to_insert,\n",
    "                vector=vector\n",
    "            )\n",
    "\n",
    "            # stop after the request number reaches = num_rows\n",
    "            counter += 1\n",
    "            if counter >= num_rows:\n",
    "                break\n",
    "\n",
    "        # check for errors at the end\n",
    "        if (len(wikipedia.batch.failed_objects)>0):\n",
    "            print(f\"Errors {len(wikipedia.batch.failed_objects)}\")\n",
    "            print(wikipedia.batch.failed_objects[-1])\n",
    "\n",
    "        print(f\"Imported {counter} items for {lang}\")\n",
    "\n",
    "# Edit the value to change the import size\n",
    "#   The 'simple' variant has 646424 rows\n",
    "num_rows = 650000\n",
    "\n",
    "# edit the value to start in the middle of the data set\n",
    "skip_rows = 0\n",
    "\n",
    "# Uncomment the language to load data for it\n",
    "import_wiki_data(\"simple\", num_rows, skip_rows)\n",
    "# import_wiki_data(\"en\", num_rows, skip_rows)\n",
    "# import_wiki_data(\"es\", num_rows, skip_rows)\n",
    "# import_wiki_data(\"de\", num_rows, skip_rows)\n",
    "# import_wiki_data(\"fr\", num_rows, skip_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECK THE UPLOAD\n",
    "\n",
    "wikipedia = client.collections.get(collection)\n",
    "response = wikipedia.aggregate.over_all(total_count=True)\n",
    "print(f\"Collection size: {response.total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT THE FIRST FEW OBJECTS\n",
    "import pprint as pp\n",
    "\n",
    "# # Uncomment if the client and collection object are undefined\n",
    "# wikipedia = client.collections.get(collection)\n",
    "\n",
    "response = wikipedia.query.fetch_objects(\n",
    "        include_vector=True,\n",
    "        limit=5\n",
    "        )\n",
    "\n",
    "for o in response.objects:\n",
    "    pp.pprint(o.properties)\n",
    "    print(o.vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   *************###############*************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST ALL COLLECTIONS            DEBUG\n",
    "\n",
    "# List all the collections on your Weaviate instance\n",
    "response = client.collections.list_all(simple=False)\n",
    "for r in response:\n",
    "    print(f\"Collection: {r}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
